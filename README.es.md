 Leer esta documentaci贸n en ingl茅s: [English version](README.md)

# Proyecto Lakehouse con Azure Synapse

## Descripci贸n general

Este proyecto implementa una plataforma anal铆tica de datos end-to-end en Azure utilizando una arquitectura Lakehouse.
La soluci贸n ingesta datos transaccionales desde Azure SQL Database hacia Azure Data Lake Storage Gen2, aplicando cargas incrementales, transformaciones de datos y buenas pr谩cticas de gobierno de datos.

El pipeline es orquestado mediante Azure Synapse Analytics y sigue la Arquitectura Medallion (capas Bronze, Silver y Gold) para garantizar escalabilidad, calidad de datos y preparaci贸n para anal铆tica.

## Arquitectura

La soluci贸n est谩 dise帽ada siguiendo el patr贸n de arquitectura Lakehouse, separando las capas de ingesta, procesamiento y anal铆tica para asegurar escalabilidad y mantenibilidad.

### Componentes principales

- **Fuente**: Azure SQL Database (sistema OLTP)
- **Orquestaci贸n**: Azure Synapse Analytics Pipelines
- **Almacenamiento**: Azure Data Lake Storage Gen2
- **Procesamiento**: Synapse Data Flows / Apache Spark
- **Capa anal铆tica**: Synapse Serverless SQL Pool
- **Gesti贸n de secretos**: Azure Key Vault

## Flujo de datos

1. Los datos se extraen de forma incremental desde Azure SQL Database utilizando una estrategia basada en watermark.
2. Los datos extra铆dos se almacenan en la capa **Bronze** en formato CSV para trazabilidad y reprocesamiento.
3. Los datos se transforman, tipifican y normalizan en la capa **Silver** utilizando formato columnar Parquet.
4. Los datasets listos para negocio se publican en la capa **Gold**, optimizados para anal铆tica y reporting.
5. Se aplican validaciones de calidad de datos entre capas para asegurar consistencia y confiabilidad.

## Arquitectura Medallion

- **Capa Bronze**: Almacena los datos en bruto tal como llegan desde las fuentes, sin transformaciones.
- **Capa Silver**: Contiene datos limpios, tipificados y estandarizados listos para procesamiento anal铆tico.
- **Capa Gold**: Proporciona datasets curados y listos para consumo por herramientas de BI y anal铆tica.

## Tecnolog铆as utilizadas

- Azure Synapse Analytics
- Azure Data Lake Storage Gen2
- Azure SQL Database
- Azure Key Vault
- Apache Spark
- GitHub

## Seguridad

- Toda la informaci贸n sensible, como cadenas de conexi贸n y credenciales, se gestiona mediante **Azure Key Vault**.
- Se utilizan **Managed Identities** para autenticar servicios sin credenciales embebidas.
- Los accesos siguen el principio de **menor privilegio**.

## Optimizaci贸n de costos

- Se utilizan SQL Pools serverless para evitar costos fijos de c贸mputo.
- Los recursos se configuran con SKUs m铆nimos adecuados para entornos de desarrollo.
- Se aprovechan formatos columnar para reducir costos de almacenamiento y mejorar el rendimiento de consultas.

## C贸mo ejecutar (alto nivel)

1. Aprovisionar los recursos necesarios en Azure (Synapse Analytics, ADLS Gen2, Azure SQL Database).
2. Configurar los Linked Services e integrar Azure Key Vault.
3. Desplegar y configurar los pipelines en Synapse.
4. Ejecutar el pipeline de ingesta y validar los datos en las capas Bronze, Silver y Gold.

## Estado del proyecto

Este proyecto se encuentra en desarrollo activo y ser谩 mejorado continuamente con funcionalidades adicionales como validaciones avanzadas de calidad de datos, monitoreo y automatizaci贸n.
